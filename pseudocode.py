
#-----Run simulator
# Run one episode according to policy (first policy is random) to select actions starting at initial_state 
# episode terminates when reaches max_steps or terminal condition (walker falls down or gets to the end)


#------Approximate Q of policy
# Approx Q is just phi*weights