## TO DO:
# - Intialize random policy and weights
# - Function to act based on policy
# - Computing basis
# - k = size of basis (calculate before computing basis?)
# - Continuous actions

#-----Run simulator
# Run one episode according to policy (first policy is random) to select actions starting at initial_state 
# episode terminates when reaches max_steps or terminal condition (walker falls down or gets to the end)


#------Approximate Q of policy
# Approx Q is just phi*weights

#----Main
# Need to initialize pi0 to have weights zero -- how to determine size of weight vector? not necessary